{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ** LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "xvH8cC7-B0bR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "ans> Logistic regression is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X.\n",
        "\n",
        "It differ from linear regression thorugh:-\n",
        "1.  the prediction done in the value by 1 or 0, whereas linear regressison has integer values.\n",
        "2. A threshold value is added.\n",
        "3. activation function is used to convert a linear regression equation to the logistic regression equation\n",
        "4. Here we use precision to predict the next weight value, whereas linear regression uses mean error( regreesion metrics) to predict."
      ],
      "metadata": {
        "id": "3CEgelpzyXri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression?\n",
        "\n",
        "ans>\n",
        "It is a mathematical tool that transforms linear combinations of features into probabilistic outputs. The sigmoid function maps any real-valued number to a value between 0 and 1, makinf it ideal for estimations.\n"
      ],
      "metadata": {
        "id": "S2gi8-pNyXua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "ans>\n",
        "Regularization in logistic regression is a technique used to prevent overfitting by penalizing large coefficients in the model. It ensures that the model generalizes well to unseen data by controlling its complexity.\n",
        "The objective function measures the error or difference between the predicted output of the model and the true output."
      ],
      "metadata": {
        "id": "jO8UWSgAyXxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "ans>\n",
        "1. ACCURACY:  Classification accuracy is the simplest evaluation metric. It is defined as the number of correct predictions divided by the total number of predictions multiplied by 100.\n",
        "2. COFUSION MMATRIX: This is a table that is often used to describe the performance of a classification model.\n",
        "3. THE ROC : The Receiver Operating Characteristic (ROC) curve is a graphical representation of the performance of a classification model at various thresholds. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR). The Area Under the ROC Curve (AUC-ROC) is a metric to evaluate the performance of a binary classification model. AUC-ROC value lies between 0 and 1, where a higher value indicates better performance.\n"
      ],
      "metadata": {
        "id": "lU2kw-WfyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "# splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "# (Use Dataset from sklearn package).\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "# Convert to pandas DataFrame (optional, but good practice)\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "dy = pd.Series(data.target, name='target')\n",
        "print(\"The initial series\")\n",
        "print(df)\n",
        "# Split data into training and testing sets\n",
        "df_train, df_test, dy_train, dy_test = train_test_split(df, dy, test_size=0.2, random_state=42)\n",
        "print(\"df_training set\")\n",
        "print(df_train)\n",
        "print(\"dy_training set\")\n",
        "print(dy_train)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(df_train, dy_train)\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "dy_pred = model.predict(df_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(dy_test, dy_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5enbwcVz2md6",
        "outputId": "31fa8606-6fce-44e7-c110-f35a29e5fc05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The initial series\n",
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                  5.1               3.5                1.4               0.2\n",
            "1                  4.9               3.0                1.4               0.2\n",
            "2                  4.7               3.2                1.3               0.2\n",
            "3                  4.6               3.1                1.5               0.2\n",
            "4                  5.0               3.6                1.4               0.2\n",
            "..                 ...               ...                ...               ...\n",
            "145                6.7               3.0                5.2               2.3\n",
            "146                6.3               2.5                5.0               1.9\n",
            "147                6.5               3.0                5.2               2.0\n",
            "148                6.2               3.4                5.4               2.3\n",
            "149                5.9               3.0                5.1               1.8\n",
            "\n",
            "[150 rows x 4 columns]\n",
            "df_training set\n",
            "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "22                 4.6               3.6                1.0               0.2\n",
            "15                 5.7               4.4                1.5               0.4\n",
            "65                 6.7               3.1                4.4               1.4\n",
            "11                 4.8               3.4                1.6               0.2\n",
            "42                 4.4               3.2                1.3               0.2\n",
            "..                 ...               ...                ...               ...\n",
            "71                 6.1               2.8                4.0               1.3\n",
            "106                4.9               2.5                4.5               1.7\n",
            "14                 5.8               4.0                1.2               0.2\n",
            "92                 5.8               2.6                4.0               1.2\n",
            "102                7.1               3.0                5.9               2.1\n",
            "\n",
            "[120 rows x 4 columns]\n",
            "dy_training set\n",
            "22     0\n",
            "15     0\n",
            "65     1\n",
            "11     0\n",
            "42     0\n",
            "      ..\n",
            "71     1\n",
            "106    2\n",
            "14     0\n",
            "92     1\n",
            "102    2\n",
            "Name: target, Length: 120, dtype: int64\n",
            "LogisticRegression(max_iter=200)\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "\n",
        "# Convert to pandas DataFrame (optional, but good practice)\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model with L2 regularization (default)\n",
        "model_l2 = LogisticRegression(penalty='l2', max_iter=200)\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "for i, col in enumerate(X.columns):\n",
        "  print(f\"{col}: {model_l2.coef_[0][i]}\") # Print coefficients for the first class as an example\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_l2 = model_l2.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "print(f\"\\nAccuracy with L2 regularization: {accuracy_l2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJiS7p7q7AHa",
        "outputId": "ceb84a23-9bcb-4a07-a9be-e5147e166f67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "sepal length (cm): -0.39345606847680076\n",
            "sepal width (cm): 0.96251768326157\n",
            "petal length (cm): -2.375124360817527\n",
            "petal width (cm): -0.9987459393434076\n",
            "\n",
            "Accuracy with L2 regularization: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        "# (Use Dataset from sklearn package)\n",
        "\n",
        "from pandas import DataFrame\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model with multi_class='ovr'\n",
        "model_ovr = LogisticRegression(multi_class='ovr', max_iter=200)\n",
        "model_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report (multi_class='ovr'):\")\n",
        "print(classification_report(y_test, y_pred_ovr, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAtj4m2K8E3x",
        "outputId": "f1800ca2-341a-406e-a102-a8f0f15920c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (multi_class='ovr'):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.89      0.94         9\n",
            "   virginica       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression\n",
        "# and print the best parameters and validation accuracy.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target, name='target')\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "              'penalty': ['l1', 'l2']}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "logreg = LogisticRegression(max_iter=200, solver='liblinear') # Use 'liblinear' solver for l1 penalty\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(logreg, param_grid, cv=5)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score (validation accuracy)\n",
        "print(\"Best Parameters: \", grid_search.best_params_)\n",
        "print(\"Best Validation Accuracy: \", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the model on the test set with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Accuracy with Best Parameters: \", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9LYy4Wv9a0N",
        "outputId": "2cf753e3-e9af-49e5-91da-eb6108c963a5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters:  {'C': 10, 'penalty': 'l1'}\n",
            "Best Validation Accuracy:  0.9583333333333334\n",
            "Test Accuracy with Best Parameters:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C0nJP_PtyX3x"
      }
    }
  ]
}